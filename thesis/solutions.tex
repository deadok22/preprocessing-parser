\clearpage

\section{Существующие решения}

Этот раздел содержит подробности реализаций подхода к решению проблемы синтаксического анализа непрепроцессированного исходного кода, состоящего в построении графа, содержащего деревья синтаксического разбора для всеx конфигураций препроцессора (см. описание подхода в подразделе \ref{subsec:unpreprocessed_parsing_methods}).

Наиболее известными реализациями этого подхода являются SuperC \cite{superc} и TypeChef \cite{typechef}.

\subsection{Общие идеи}
\label{subsec:commonideas}

Построение графа, содержащего деревья синтаксического разбора для всех конфигураций препроцессора, так или иначе включает в себя два этапа:

\begin{enumerate}

\item Частичное препроцессирование или лексический анализ, сохраняющий конфигурацию.

Выполняется интерпретация инструкций препроцессора, с сохранением информации об условных ветвлениях, и лексический анализ;
\item Синтаксический анализ, сохраняющий конфигурацию.

Используется результат выполнения предыдущего этапа для построения графа разбора, содержащего синтаксические деревья для всех конфигураций препроцессора;

\end{enumerate} 

\subsubsection{Лексический анализ, сохраняющий конфигурацию}
\label{subsubsec:configurationpreservinglexing}

Работа, выполняемая на этом этапе, условно состоит из двух частей --- интерпретации инструкций препроцессора и проведения лексического анализа входного текста. Условность здесь состоит в том, что эти части могут выполняться одновременно, если языком препроцессора используются те же лексемы, что и языком программирования.

Инструкции препроцессора интерпретируются аналогично тому, как это делает сам препроцессор, за тем исключением, что строятся варианты выходных последовательностей одновременно для всех конфигураций. Более подробно работа лексического анализатора, сохраняющего конфигурацию описана в подразделе \ref{lexingandpreprocessing} на примере его реализации в проекте SuperC.

Результатом выполнения этого этапа является последовательность лексем и узлов условного ветвления, представленная в том или ином виде. Узлы ветвления представляют собой наборы из подпоследовательностей лексем и узлов условного ветвления, предваренных так называемыми условиями наличия (presence conditions). Каждый такой набор внутри узла ветвления соответствует некоторой альтернативной ветви условной компиляции в исходном непрепроцессированном коде.

\subsubsection{Синтаксический анализ, сохраняющий конфигурацию}

Этот этап состоит в преобразовании входной последовательности из лексем и узлов условного ветвления в дерево разбора, содержащее вершины, соответствующие конструкциям языка программирования, как в обыкновенном абстрактном синтаксическом дереве, а также вершины условного ветвления, каждая ветвь которых соответствует некоторой альтернативной ветви условной компиляции.

Появление узла ветвления во входной последовательности лексем может приводить к различной интерпретации лексем и уже разобранных конструкций, предшествующих текущей позиции. Это может привнести существенные сложности при разборе альтернативных ветвей условной компиляции. Так, в листинге \ref{lexemeinterpretation} выражение справа от знака присваивания может быть либо числовой константой, либо аддитивным выражением. Это потребует переноса места ветвления в позицию следующую за символом равенства.

\begin{minipage}{\linewidth}
\begin{lstlisting}[caption={Пример различной интерпретации лексем, предшестующих блоку условной компиляции},label=lexemeinterpretation,language=C]
int main(int argc, char ** argv) {
	int x = 0
#ifdef RET_1
	+ 1	
#endif
	;
	return x;	
}
\end{lstlisting}
\end{minipage}

Помимо проблемы выбора места ветвления, имеет место проблема выбора места слияния. Она состоит в том, что лексемы, следующие за узлом условного ветвления могут быть проинтерпретированы по-разному для каждой из альтернативных ветвей.

Слишком раннее ветвление, равно как и слишком позднее слияние могут привести к многократному разбору одних и тех же участков кода, что приводит к существенному снижению производительности и увеличению объёма используемой памяти.

\begin{minipage}{\linewidth}
\begin{lstlisting}[caption={Выбор точки слияния подпарсеров оказывает существенное влияние на скорость разбора},label=subparsersmerge,language=C]
#ifdef USE_LONG
#define RETURN_TYPE long
#else
#define RETURN_TYPE int
#endif

RETURN_TYPE function() {
	...
	/* function body */	
	...	
	return 0;
}
\end{lstlisting}
\end{minipage}

В листинге \ref{subparsersmerge} приведен пример кода, неудачный выбор точки слияния в котором, может привести к существенному увеличению количества времени, необходимого для разбора. Как видно, тип возвращаемого значения функции зависит от макроопределения USE\_LONG, что приведет к порождению двух ветвей разбора. Если точка слияния выбрана неудачно, то тело функции, следующей далее, может быть разобрано многократно.

\subsection{Синтаксический анализ непрепроцессированного кода на языке С}

На языке программирования С с момента его создания было написано огромное количество программного обеспечения различной сложности --- в том числе и наиболее сложные программные системы: ядра операционных систем, системы управления базами данных, и т. д.. В связи с этим имеется большой спрос на средства работы с исходным кодом на языке С --- браузеры кода, средства автоматического поиска ошибок, инструменты для рефакторинга, что, в свою очередь, пробудило интерес исследователей к проблеме синтаксического анализа непрепроцессированного кода на языке С.

\subsubsection{SuperC}

Проект SuperC является частью проекта xtc\footnote{eXTensible Compiler --- \url{http://cs.nyu.edu/rgrimm/xtc/}} Нью-Йоркского Университета. В этом проекте успешно решается проблема синтаксического анализа кода на языке С с инструкциями препроцессора, что подтверждается успешным разбором кода ядра Linux для архитектуры x86.

SuperC использует описанный в подразделе \ref{subsec:commonideas} двухэтапный подход. Рассмотрим более подробно каким образом реализованы эти этапы.

\paragraph{Лексирование и препроцессинг}
\label{lexingandpreprocessing}

Для того, чтобы сформировать единицу компиляции, препроцессору, сохраняющему конфигурацию необходимо обработать следующие инструкции препроцессора: объявления и удаления макроопределений, директивы включения файлов, вызовы макроопределений.

Для корректной обработки этих инструкций, препроцессору, среди прочего, необходимо производить разрешение имён макроопредлений. Это решается при помощи поддержания таблицы макроопределений на протяжениип обработки входных файлов. В эту таблицу вносятся записи, соответствующие директивам препроцессора \#define и \#undef. При этом объявления равно как и удаления макроопределений могут появляться в различных ветвях статических условных блоков, что приводит к тому, что, в зависимости от конфигурации один и тот же вызов макроопределения может быть проинтерпретирован совершенно по-разному --- возможны не только различные варианты макроподстановок, но и сами вызовы. Поэтому записи в таблице макроопределений ассоциируются с условиями их наличия, используемыми впоследствии для разрешения имён в различных ветвях условной компиляции.

\autoref{macrocalls} иллюстрирует некоторые случаи различных вызовов и подстановок макроопределений. Так, в случае наличия в конфигурации препроцессора объявления OP\_FUN, в двенадцатой строке будет произведена подстановка макроопределения без аргументов. Eсли же OP\_FUN окажется необъявленным, но будет объявлен OP\_ID --- будет произведена подстановка макроопределения с одним аргументом. В случае, если оба этих объявления не будут присутствовать, лексема, соответствующая имени макроопределения должна быть пропущена, а лексемы, соответствующие возможным аргументам вызова, проанализированы на предмет наличия других вызовов макроопределений.

\begin{minipage}{\linewidth}
\begin{lstlisting}[caption={Различные вызовы макроопределения при различных конфигурациях препроцессора},language=C,label=macrocalls]
#ifdef OP_FUN
int __op_fun(int x) {
	return x + 2;
}
#define OP __op_fun
#elif OP_ID
#define OP(X) X
#endif

int main(int argc, char ** argv) {
	int x = 0;
	x = OP(x);
	return x;	
}
\end{lstlisting}
\end{minipage}

Таким образом, различные варианты подстановки для одного и того же вызова макроопределения, равно как и различные вызовы макроопределений, полученные из тех же лексем, порождают неявные блоки условной компиляции, которые должны быть обработаны как препроцессирующим лексером, так и парсером на следующем этапе точно таким же образом, как и явные блоки условной компиляции, заданные при помощи директив препроцессора \#if, \#ifdef, \#ifndef и др..

Вызовы макроопределений могут также пересекать границы блоков условной компиляции, что приводит к необходимости специальной обработки таких ситуаций, состоящей в дубликации лексем, составляющих вызов макроопределения. В листинге \ref{hoisting} приведен пример такой ситуации. Лексемы, следующие за блоком \#ifdef \dots \#endif, а именно, <<x, 10)>> могут являться частью вызова макроопределения в случае, если объявлено макроопределение MACRO\_MUL.

\begin{minipage}{\linewidth}
\begin{lstlisting}[caption={Вызов макроопределения пересекает границу блока условной компиляции},language=C,label=hoisting]
#define MUL(X, Y) ((X) * (Y))

int multiply(int x, int y) {
	return x * y;
}

int main(int argc, char ** argv) {
	int x = 1;
	x =
#ifdef MACRO_MUL
	MUL(
#else
	multiply(
#endif
		x, 10);
	return x;	
}
\end{lstlisting}
\end{minipage}

Как уже было сказано ранее, для корректной обработки статических условий необходимо поддерживать условия наличия тех или иных участков кода. При этом трансформация статических условий в условия наличия зачастую требует частичного вычисления булевых выражений. Разработчики SuperC используют в своём решении двоичные диаграммы принятия решений (см. \cite{bdd}), а именно --- библиотеку JavaBDD\footnote{\url{http://javabdd.sourceforge.net/}}. Статические условия трансформируются в двоичные диаграммы принятия решений следующим образом:

\begin{enumerate}
\item Числовые константы заменяются на true и false, в зависимости от их значения;
\item Свободные макроопределения (переменные конфигурации) заменяются на переменные в BDD;
\item Арифмитические выражения заменяются на переменные в BDD;
\item Выражения, проверяющие объявлено ли макроопределение, такие, как  defined(MACRO), \#ifdef, \#ifndef и пр., заменяются на дизъюнкцию условий наличия, при которых это макроопределение объявлено.
\end{enumerate}

Это позволяет эффективно сравнивать условия наличия, а также выявлять недостижимые ветви условной компиляции.
 
Результатом работы препроцессирующего лексера является направленный ациклический граф, состоящий из лексем с условиями их присутствия. В SuperC этот граф представлен последовательностью лексем языка с дополнительными лексемами, обозначающими точки ветвления и границы ветвей условной компиляции.

\paragraph{Синтаксический анализ}

Парсер, применяемый в проекте SuperC, основывается на LR-анализаторе (см. \cite{aho}), генерируемом парсер-генератором Bison\footnote{\url{http://www.gnu.org/software/bison/}}.

Работа LR-анализаторов строится на основе стека, содеражащего терминальные и нетерминальные символы грамматики. Каждый шаг алгоритма LR-анализатора представляет собой одно из четырех возможных действий: 

\begin{enumerate}
\item Сдвиг --- помещение лексемы из входного буффера на стек;
\item Редукция --- замена нетерминалом одного или нескольких верхних элементов стека;
\item Принятие --- успешное завершение разбора;
\item Отвержение --- завершение разбора с ошибкой. 
\end{enumerate}

Действие выбирается в зависимости от входной лексемы и текущего состояния стека.

Разработчики SuperC аргументируют выбор именно LR-анализатора в качестве основы для парсера сохраняющего конфигурацию следующими пунктами:

\begin{itemize}
\item Возможность использования LR парсер-генератора для создания LR-таблиц, что значительно упрощает разработку;
\item Удобство использования состояния парсера для обработки ветвей условной компиляции: достаточно использовать персистентный стек, реализованный на основе односвязного списка, в качестве стека LR-анализатора;
\item Поддержка LR-парсерами широкого класса языков программирования.
\end{itemize}

Сам же FMLR-анализатор (Fork Merge LR parser) представляет собой алгоритм похожий по структуре на планировщик задач, где задачами выступают LR-подпарсеры. Алгоритм поддерживает очередь парсеров с соответствующими им условиями наличия и состояниями чтения входного буфера.

На каждом шаге алгоритма из очереди вынимается один парсер, для которого, в зависимости от следующего символа и состояния парсера выполняется одно из следующих действий:

\begin{itemize}
\item LR-действие, выбранное подпарсером и помещение подпарсера в конец очереди;
\item Если следующим входным символом является точка ветвления, --- создание подпарсеров для каждой из следующих возможных лексем, помещение этих подпарсеров в конец очереди.
\end{itemize}

После выполнения действия очередь парсеров исследуется на возможность слияния нескольких подпарсеров в один --- это возможно лишь в том случае, если парсеры находятся на одном и том же месте во входном буфере, их LR-стеки совпадают, а также элементы на вершинах стеков соответствуют нетерминалам, для которых возможны ветвления и слияния. Каждое подмножество парсеров, для которого верны указанные условия, заменяется одним парсером, условие наличия которого выражено дизъюнкцией условий наличия парсеров из подмножества.

Стоит заметить, что выбор подмножества нетерминалов, для которых возможны ветвления и слияния, хотя и позволяет описать вид синтаксического дерева, явно указав синтаксические единицы, которые могут быть заменены на вершины-ветвления, привносит также некоторые сложности: отсутствие аннотаций для нетерминальных символов с продукциями некоторых видов может привести к порождению экспоненциального количества подпарсеров. 

Например, если продукция для некоторого нетерминала представляет собой некоторую последовательность из нетерминалов, непомеченных аннотацией возможного ветвления и слияния, то каждый элемент последовательности, полученный из блока условной компиляции, приведет к порождению двух подпасреров, слияние которых будет возможно только при завершении разбора всей последовательности. 

\subsubsection{TypeChef}

TypeChef --- исследовательский проект, объединивший усилия исследователей из многих университетов, имеющий своей целью поиск ошибок, вызванных интенсивным использованием препроцессора, в программах на языке С.

В основе алгоритма разбора непрепроцессированного исходного кода так же, как и в случае SuperC, лежит двухэтапный подход, поэтому далее будут описаны только особенности, отличающие TypeChef от SuperC.

\paragraph{Лексирование и препроцессинг}

Функциональность препроцессирующего лексера, сохраняющего конфигурацию, реализованного в проекте TypeChef аналогична функциональности, реализованной в аналоге --- SuperC (см. подраздел \ref{lexingandpreprocessing}).

Любопытной особенностью реализации препроцессирующего лексера в TypeChef является представление результата в виде последовательности лексем, где каждая лексема предварена условием её наличия. При этом отстутсвуют явные указания начал и концов ветвей условной компиляции --- при синтаксическом анализе альтернативы и пропуски вычисляются при помощи сравнения условий наличия и решения задачи выполнимости булевых формул \cite{garey}.

Задача выполнимости булевых формул в TypeChef решается с помощью библиотеки Sat4j\footnote{\url{http://www.sat4j.org/}}.

\paragraph{Синтаксический анализ}

Авторы проекта TypeChef предлагают использовать библиотеку парсер-комбинаторов для реализации синтаксических анализаторов, поддерживающих условную компиляцию.

Основной идеей этой библиотеки является сокрытие логики обработки ветвей условной компиляции в нексольких парсер-комбинаторах, которые могут быть использованы для создания парсеров, позволяющих производить синтаксический анализ, учитывающий одновременно несколько ветвей условной компиляции.

\todo{дописать сюда перечисление парсер-комбинаторов из библиотеки, если останется время}

Более подробно о парсер-комбинаторах, предлагаемых в этом решении, можно прочесть в \cite{typechef2}.

Такие библиотеки парсер-комбинаторов были реализованы на языках Haskell и Scala в рамках проекта TypeChef. Версия библиотеки, написанная на Scala, используется в TypeChef для реализации синтаксических анализаторов для языков C и Java, поддерживающих условную компиляцию.

\subsection{Возможности адаптации решений к другим языкам}
\label{subsec:solutionsadaptation}

Несмотря на то, что изученные проекты TypeChef и SuperC были изначально нацелены на синтаксический анализ языка С с инструкциями препроцессора cpp, они предоставляют возможности для распространения используемых подходов на другие языки. 

Однако, имеются препятствия к такому их использованию: может потребоваться реализация препроцессирующего лексера <<с нуля>>, специальные обозначения для мест возможных условных ветвлений, модификации грамматики целевого языка, связанные с поддержкой библиотекой определенных классов языков, и другие.

\subsubsection{TypeChef}

Для того, чтобы использовать TypeChef для синтаксического анализа кода на языке отличном от С, требуется описать целевой язык, используя библиотеку парсер-комбинаторов на языке Scala.

Описание целевого языка при помощи парсер-комбинаторов вызвать некоторые проблемы, связанные, например, c использованием леворекурсивных правил в грамматике: правила вида $A \to A a | a$ не могут быть переписаны явно --- потребуется либо написание праворекурсивной версии этого правила с последующей трансформацией полученного поддерева, либо аналогичная конструкция --- такая, как, например, в листинге \ref{scalaleftrec}.

\begin{minipage}{\linewidth}
\begin{lstlisting}[caption={Описание леворекурсивных правил с парсер-комбинаторами TypeChef},label=scalaleftrec,language=Scala]
class LeftRecursiveAParser extends MultiFeatureParser {
	def A: MultiParser[A] = rep1(a) ^^ {
		case first :: rest => rest.foldLeft(new A(first)) {
			(l, r) => new A(l, r)
		}
	}
}
\end{lstlisting}
\end{minipage}

Для использования этих парсер-комбинаторов требуется хорошее представление об их работе и о структуре синтаксического дерева, которое разработчик хочет получать в качестве результата работы такого парсера. В случае неудачного выбора мест ветвления и слияния, производительность такого парсера может существенно деградировать.

\subsubsection{SuperC}

Серьёзных усилий требует и адаптация к другому языку программирования синтаксического анализатора из проекта SuperC. Для реализации синтаксического анализатора языка программирования с инструкциями препроцессора, SuperC требует от разработчика следующее:

\begin{itemize}
\item Описание лексера со специальными аннотациями, указывающими какие лексемы являются запятыми, скобками, решёткой, двойной решёткой (эти лексемы используются препроцессором языка С);
\item Описание грамматики языка для парсер-генератора Bison;
\item Аннотации к нетерминальным символам грамматики, указывающие, следует ли парсеру производить ветвления и слияния на узлах, соответствующих продукциям для этого нетерминального символа;
\item Реализация семантических действий при разборе той или иной синтаксической конструкции --- например, построение узлов AST.
\end{itemize}

Хочется заметить, что это достаточно большой объём работы, которая требует не только квалификации разработчика в области LR анализаторов, но и хорошей степени знакомства с проектом SuperC.
